{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Understanding \n",
    "\n",
    "___\n",
    "\n",
    "Rasa NLU is an open-source natural language processing tool for intent classification, response retrieval and\n",
    "entity extraction in chatbots.\n",
    "\n",
    "In this section, you will enable your bot to understand the user inputs by building a Rasa NLU model.\n",
    "\n",
    "This model will take unstructured user inputs and extract structured data in a form of intents and entities:\n",
    "\n",
    "   - **Intent** - a label which represents the overall intention of the user 's input\n",
    "   - **Entites** - important detail which an bot should extract and use to steer the conversation\n",
    "\n",
    "For example, taking a sentence like\n",
    "\n",
    "> \"I am looking for a Mexican restaurant in the center of town\"\n",
    "\n",
    "and returning structured data like\n",
    "\n",
    ">```\n",
    "{\n",
    "      \"intent\": \"search_restaurant\",\n",
    "      \"entities\": {\n",
    "        \"cuisine\" : \"Mexican\",\n",
    "        \"location\" : \"center\"\n",
    "      }\n",
    " }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<strong>Before you start writing the code, please run this command so that you can asynchronous Rasa code in Jupyter Notebooks since Jupyter Notebooks already run on event loops.</strong>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop ready.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "print(\"Event loop ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating the NLU training data:\n",
    "To train the NLU model you will need some labeled training data. Rasa NLU training data samples consist of the following components:\n",
    "\n",
    "- intent label which starts with a prefix  **##**\n",
    "- examples of text inputs which correspond to that label\n",
    "- entities which follow the format [entity_value] (entity_label)\n",
    "\n",
    "We will start by generating some training data examples by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'data/nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > data/nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Designing the training pipeline:\n",
    "\n",
    "Once the training data is ready, we can define the NLU model. We can do that by constructing the processing pipeline which defines how structured data will be extracted from unstructured user inputs: how the sentences will be tokenized, what intent classifier will be used, what entity extraction model will be used, etc. Each component in a training pipeline is trained one after another and can take inputs from the previously defined component as well as pass some information to subsequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'configuration' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"WhitespaceTokenizer\"       # splits the sentence into tokens           \n",
    "- name: \"CRFEntityExtractor\"                   # uses the pretrained spacy NER model\n",
    "- name: \"CountVectorsFeaturizer\"     # transform the sentence into a vector representation\n",
    "- name: \"EmbeddingIntentClassifier\"   # intent classifier\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training the first Rasa NLU Model\n",
    "Now, we're going to train the NLU model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a \"greet\" intent. Let's define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa.nlu.training_data import load_data\n",
    "from rasa.nlu.config import RasaNLUModelConfig\n",
    "from rasa.nlu.model import Trainer\n",
    "from rasa.nlu import config\n",
    "\n",
    "def train_nlu_model():\n",
    "    # loading the nlu training samples\n",
    "    training_data = load_data(\"data/nlu.md\")\n",
    "\n",
    "    # trainer to educate our pipeline\n",
    "    trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "    # train the model!\n",
    "    interpreter = trainer.train(training_data)\n",
    "\n",
    "    # store it for future use\n",
    "    model_directory = trainer.persist(\"./models/current\", fixed_model_name=\"nlu\")\n",
    "    \n",
    "    return interpreter, model_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train the model using the previously defined data and model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\utils\\expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\utils\\adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\utils\\multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\mesh_tensorflow\\ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\mesh_tensorflow\\ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\models\\research\\neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\rl\\gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Entry Point [tensor2tensor.envs.tic_tac_toe_env:TicTacToeEnv] registered with id [T2TEnv-TicTacToeEnv-v0]\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensor2tensor\\utils\\trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\nlu\\classifiers\\embedding_intent_classifier.py:544: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\nlu\\classifiers\\embedding_intent_classifier.py:547: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:256: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:257: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:258: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:259: DatasetV1.output_classes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(dataset)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:299: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:301: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims` instead.\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:679: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\utils\\train_utils.py:681: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|█████████████████████████████████████████████████| 300/300 [00:13<00:00, 22.00it/s, loss=0.572, acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\salome\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\rasa\\nlu\\classifiers\\embedding_intent_classifier.py:678: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initially it will throw some warnings related to Tensorflow, ignore the warnings\n",
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Testing the model\n",
    "\n",
    "We have trained the first version of our NLU model! Let's test it on various inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper function to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))\n",
    "\n",
    "#change the input message with your prefered inputs\n",
    "input_message = \"What talks would you recommend to data scientists?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Handling out-of-scope inputs\n",
    "When dealing with conversational AI, out-of-scope user inputs are very common challenge. These inputs represent the user requests which have nothing to do with the chatbot's job. While it's very challenging to provide a sensible answer to each out-of-scope input, it's important to enable your chatbot to identify such inputs and guide the user back to the conversation. First, let's enable our assistant to identify out-of-scope inputs. To do that, we will add a new intent called out-of-scope to our training dataset and provde some corresponding inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the model and see how it deals with out-of-scope inputs now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"I want pizza\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Adding synonyms\n",
    "Synonyms are a very useful Rasa NLU feature which maps extracted entities to the same name. It's used when some extracted values have to be normalised so that they could be used to query the database or make an API call. In our example, the occupation of the relevant audience is a good candidate for the synonym because users can provide the same occupation in a variety of different ways (for example, Machine Learning and ML). Let's update our training examples with synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the NLU model with synonyms, we have to add the synonyms component to the model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'configuration' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"WhitespaceTokenizer\"       # splits the sentence into tokens          \n",
    "- name: \"CRFEntityExtractor\"                   # uses the pretrained spacy NER model\n",
    "- name: \"CountVectorsFeaturizer\"     # transform the sentence into a vector representation\n",
    "- name: \"EntitySynonymMapper\"\n",
    "- name: \"EmbeddingIntentClassifier\"   # intent classifier\n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain the NLU model and test the performace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.model:Starting to train component WhitespaceTokenizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component CRFEntityExtractor\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component CountVectorsFeaturizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component EntitySynonymMapper\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component EmbeddingIntentClassifier\n",
      "Epochs: 100%|█████████████████████████████████████████████████| 300/300 [00:09<00:00, 31.20it/s, loss=0.540, acc=1.000]\n",
      "INFO:rasa.utils.train_utils:Finished training embedding policy, train loss=0.540, train accuracy=1.000\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Successfully saved model into 'C:\\Users\\Salome\\Desktop\\desktopDocs\\test-project\\models\\current\\nlu'\n"
     ]
    }
   ],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "See how 'machine learning engineers' now gets mapped to 'ML':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"For machine learning engineers\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Implementing multi-intents\n",
    "The NLU model we have built so far works pretty well, but it only supports inputs with only one intent per user input. In this step, we will use a tensorflow embedding model to enable the assistant to recognise multi-intents - more than one intention per user input. Let's start by defining multi-intents in our training data. Multi-intents are defined in a very similar way as regular intents, the only difference is that the label names consists of intent tokens and a character of your choice that separates them, for example intent_token1+intent_token2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:recommend_session\n",
    "- What presentation would you recommend to [data scientists](relevant_audience)?\n",
    "- Which talks are relevant to people in [Machine Learning](relevant_audience:ML) field?\n",
    "- I work as a [product manager](relevant_audience). What sessions would you recommend for me to attend today?\n",
    "- Are the any talks you could recommend to [machine learning](relevant_audience:ML) folks to attend tomorrow?\n",
    "- Which talks today are relevant to [developers](relevant_audience)?\n",
    "\n",
    "## intent:speaker\n",
    "- Who is the speaker?\n",
    "- And who's presenting?\n",
    "- What's the name of the presenter?\n",
    "- Who's presenting?\n",
    "- Who's speaking?\n",
    "- The name of the speaker?\n",
    "\n",
    "## intent:length\n",
    "- How long is the session?\n",
    "- And what's the length of this?\n",
    "- How long is this session?\n",
    "- Can you tell me how long this session is?\n",
    "- Is the session long?\n",
    "\n",
    "## intent:abstract\n",
    "- Show me the abstract\n",
    "- Can you give me more details about this talk?\n",
    "- Is there a description of this presetnation?\n",
    "- Can you show me an abstract of this talk?\n",
    "- Show me the abstract, please\n",
    "- Can you show me the summary of the talk?\n",
    "- What this talk will be about?\n",
    "\n",
    "## intent:thanks\n",
    "- Thank you.\n",
    "- very useful. thank you so much!\n",
    "- Thanks\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "\n",
    "## intent:inform\n",
    "- to [Data Scientists](relevant_audience)\n",
    "- relevant to [machine learning engineers](relevant_audience:ML)\n",
    "- for [product](relevant_audience) people\n",
    "\n",
    "\n",
    "## intent:out-of-scope\n",
    "- I want pizza\n",
    "- please help with my ice cream it's dripping\n",
    "- no wait go back i want a dripping ice cream but a cone that catches it so you can drink the ice cream later\n",
    "- i want a non dripping ice cream\n",
    "- hey little mama let em whisper in your ear\n",
    "- someone call the police i think the bot died\n",
    "- show me a picture of a chicken\n",
    "- neither\n",
    "- I want french cuisine\n",
    "- i am hungry\n",
    "- restaurants\n",
    "- restaurant\n",
    "- you're a loser lmao\n",
    "- can i be shown a gluten free restaurant\n",
    "- i don't care!!!!\n",
    "- i do not care how are you\n",
    "- again?\n",
    "- oh wait i gave you my work email address can i change it?\n",
    "- hang on let me find it\n",
    "- stop it, i do not care!!!\n",
    "- really? you're so touchy?\n",
    "- how come?\n",
    "- I changed my mind\n",
    "- what?\n",
    "- did i break you\n",
    "\n",
    "\n",
    "## intent:speaker+length\n",
    " - Who is the presenter? Also, how long is the talk?\n",
    " - Who is the speaker and how long is the session?\n",
    " - Is the session long and who is presenting?\n",
    " - Do you know who is the presenter of the session? And how long is the session?\n",
    " - Is the talk long and who is presenting?\n",
    " - Who is the speaker? And how long is the talk?\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's modify the configuration of the model pipeline to use the tensorflow_embedding model with multi-intent support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'configuration' (str) to file 'config.yml'.\n"
     ]
    }
   ],
   "source": [
    "configuration = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"WhitespaceTokenizer\"       # splits the sentence into tokens\n",
    "  intent_split_symbol: \"+\"            #sets the delimiter string to split the intent label\n",
    "- name: \"CRFEntityExtractor\"                   # uses the pretrained spacy NER model\n",
    "- name: \"CountVectorsFeaturizer\"     # transform the sentence into a vector representation\n",
    "- name: \"EntitySynonymMapper\"\n",
    "- name: \"EmbeddingIntentClassifier\"   # intent classifier\n",
    "  \n",
    "\"\"\" \n",
    "\n",
    "%store configuration > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the model with the new pipeline and test the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, model_directory = train_nlu_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how a two-question input now gets recognised as a multi-intent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Who is the speakers and how long is the session?\"\n",
    "pprint(interpreter.parse(input_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just implemented the natural language understanding part of your assistant which means that your assistant can now understand you. In the next part, we will explore more about Rasa NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
